{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import autograder\n",
    "import q1\n",
    "import q2\n",
    "import q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural & Artificial Vision - HW5\n",
    "\n",
    "In this assignment, we will explore supervised and unsupervised learning.\n",
    "\n",
    "If you get stuck, suggested resources include:\n",
    "- https://www.cs.cmu.edu/~16385/s17/Slides/9.5_Backpropagation.pdf\n",
    "- https://compneuro.neuromatch.io/tutorials/Bonus_Autoencoders/student/Bonus_Intro.html"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAACgCAYAAAAhKfa4AAAgAElEQVR4Ae2dW6xdxXnH/dC4iLdTlF6kKoowB2LxYCk5JrSKBZYxrlJEsVDlUrsoSW2DuQiqpKlwi9u6VYiDSCqqpFaSl0RKTiJEVIRsOSIoCq6UloBqUbmllKOkRuVSjIwFaZunVf2W823PWWfWfWZd9vqPtDVrr8vMN//1rd+ePWsu6xIFKSAFpIAUGKQC6wZplYySAlJACkiBRICWE0gBKSAFBqqAAD3QGyOzpIAUkALRAf1fb/x38tVvfSf544e+kPzBH/1psm33/mTj9p3JwqYt6Ydt9nGMcziXaxSkQJkC8q0yhXR87ApEAfS//sdK8vCXv5ZsvW1f8gtXfKjR5/rf25umQVoKUsAUkG+ZEoqnoEBQQP/gn55PPvrxe1YB+ZKrrkluPfDJ5JGvfD35xhPHk+//8EfJiys/Ts6/8276YZt9HOMczuUaF+ykSdoK01VAvjXdez/lkgcB9OmXVtImCoPq+sWl5BOf/ovk8RNPJ//3s5/V1pdrHj/xveQP/+QvE9KydGkGIS+F6Sgg35rOvVZJ1yrQGtD3H354BtD1V25ODn3hS8lP/+d/1+bUcA9pkSZpG6jJU2H+FZBvzf89VgmLFWgM6LfOnU9u3nvfDJp3H3ooOfPq68W5tThK2uRhkCZvbFCYPwXkW/N3T1WiZgo0AvRzL5xOrr7x1hSWl193U/LMs921D5MXeQJqbMAWhflRQL41P/dSJWmvQG1AP3b8qeTSjdemgLxhzx3JK6+90d6KmimQJ3kDaWzBJoXxKyDfGv89VAnCKlAL0NRuDM77Hjgc1pIGqWGDQVo16QYCDugS+daAboZMGYwClQFNu6A1awwBzqagQRrb1CZtqowrlm+N637J2u4UqAxoeyFI08LQgjV3YKPC+BSQb43vnsnibhSoBGjr7sTLuT7anMukwCZ7cagueGVqDeu4fGtY90PWDEuBUkAzUMC6tnXZW6OuTNhmdmowS131+jlfvtWP7sp1PAqUAprRe4CPPshDD9ZPGpsVhq+AfGv490gW9qtAIaCZ/wA4M4ov5iCUUBJgo4041NwdoVSNk458K46uSnW+FCgEtE18xFDrsQRs5UcF2xWGq4B8a7j3RpYNR4FcQDOtY1p7XtwcdG6N2EVn7o71ixfm7dBUpbHVbpa+fKuZbrpqegrkApr5nAE0M8qNLTCTHrZTBoXhKSDfGt49kUXDVCAX0EyYD+SY9nNsgWlOsZ0FAxSGp4B8a3j3RBYNUwEvoFlKCMAxcX6T+Zz7Lio226T/Wj6r77uxOn/51mo99E0KFCngBTTrAgJoVjcZa8B2ykBZFIajgHxrOPdClgxfAS+gWbwVuLEE1VgDtlMGyqLQnQJv/7R4sQb5Vnf3QjmNXwEvoG0AAesENgknT55MduzYkaxbty7ZsGFDcurUqVXJHDx4MD22tLS0an/IL9gOoDVoJaSq5Wnd+9Unkj/75neTM2+e855cx7eOHj2a4CP4ER98anl5OY051leQb/Wl/PTy9QJ62+79KdxYzLVuOHv2bPoAraysJMeOHUsfrF27ds2SMTjbAzc7EHgD2wE0ZVHoTgEA/d6PHU4/PlBX8S18yMB85MiRhO+EAwcOzGANqPsK8q2+lJ9evl5Ab9y+M4UbK263DQsLCwkfAjVrwMzDxYPHJ1bAdgBNWRS6U8AFtA/UVXyLH3T8JFtLNv/hGBWAvoJ8qy/lp5evF9ALm7akcDv/zrutFbGHjWYOQN1VzQfbAbRBQvGFWm2fOlCjXti8vdC37F8XzRnZYICm2azPYL512W99LFk+ubr5rk+7lPf8KVAI6BCrc1NLpsbDQ8Vf1K4CD9Glv7lTgP55c0OfYCbv99/52WTzp/82ueyjn0gBnedb1rTh+yE3eLtNZl35k5sPvnXJh26c+dbWQ18WqF2BtB1MAS+g7W/oyz850zqjvmo9/A19zweuTX5t9wPpg8RDVNbDoHVhlUCSbeL49b2fSd63/6EZzDb89p4U0D7fotmCH3M+1u7sSmo/9tmmD/ecLratieP9t+xPPvipR2dlE6i7UH9aeXgBbS9yQswIZw+V7y+rKzUPJC8QaQbhAaUmRY2pabAXOdfvvjPhwaEWJ0g3VbPadfwA7nrkG6nWv/Lxv5qBy2rv6F/kW1ZD5t77gtWu+dH3BXwIf7N3Hr5zsvua+J35lr2APvrdfxSos8LqexAFvIC2rlDLT55olQkPHA+LPVhFifG3lWYQalE8NPbGPu9hLEqLY25XKMAhSJcpFub4Rw7+3RowG6Bpgy7yraIfc/snxo+3L9Akgv9YDdx3jm9fE79zfctNU6B21dB2CAW83h5iMIG9FOTBKoMt5/Jgue2OQJp9ZTXvPBGyA1UE6Tylwu5H52wzhwH6H/7tx+nAIV7e+gZBFQEaP8jzB47hY/y4V6kMWImb+l3Wtyw9iwVqU0JxWwW8gG46HBcY84AYnGmyINBmyMOV13ZoD2a2tlznYcsK4RvqLUhnVYrzHRAblC3mHwyhyLesiSP7o4x/2I88cTbwY27BQG7fi+KmfufzLV8+ArVPFe2ro4AX0E0ntDEQA2PgasFe/lj3KM4zeHNO3kNl+7m+TiiaLEmQrqNk/XOB8xV3fS4FtPsCjeYNQpFvAVp7B8GPPN8NztbEAaBtP8eywXwmu9/3Pe9c2+/zuyLf8uXBPoE6TxntL1PAC2guYqpO/ooydWfVYDUSHNyt1XC9jSDkAWTbPW4PRDYf25+tWWfPy35nilRsZ1pLXxCkfaq03+fCGSC7zR0cs1DkW9xra0vmR95eFOMvtp8YX3N9yNI2n7HvRXHeubbf53dlvlWUn0BdpI6O+RTIBbRNqs7k97GDPRDZBy5vf5k9LDIAoIsm7Beky1Ssd9wHZ0sBMLkhpm+Zz7j55W3buXX8ropv5eVn+9HDmn6Ib/ns15Ljz79ohxVLgZkCuYDuclkiq11nayz2AM2srbBRZ8krQbqCoBVOKYKz7/KYvlXHZ+r6XR3f8pU7u0+gziqi71kFcgHNiV0t7EnvjexLRGo17Ks7aqzuorGCdNYl6n2vC2dLPZZv1QF0Xb+r61tW1rJYoC5TaLrHCwHNQBWaCtZfuTk58+rrUVWivZH2aV4OEeytvX2vkjk2Yis21xlkI0hXUXftOU3hTEoxfMt6D/HDnv03Rp72jsQtSVW/a+pbbl5l21lQ3/7ot3OnbS1LS8fnQ4FCQFNEG1hw96GHopaYN+bUlnm4+PDg+B6yIiOwEThjc90gSNdTrA2cLadQvmXgNd9xY45ZsPPsO3FVv2vjW25+VbYF6ioqTeOcUkCffmklhR7ge+bZ5werCrZhIx9sbhIE6WqqhYAzOXXtWzR/0O5cN4Twrbp5cr5A3US1+bqmFNAU9/7DD6fgu/y6m5JXXntjcApgE7YBZ2xtEwTpYvVCwdly6cq3aG9uAueQvmVlrhsL1HUVm5/zKwGa4t68974UgDfsuWNwpccm4IyNIYIg7VcxNJwtlyn5lpW5SSxQN1Ft3NdUBvRb584nV994awrCfQ8cHkypsQU4Yxs2hgqC9GolY8GZXKbmW6uVrf9NoK6v2VivqAxoCvjcC6eTSzdeOxhIG5yxCdtCB0H6gqIx4Wz3bGq+ZeVuE2dBzSRVeYv1tslH1/anQC1AY+Zjx5+aQZqmhT7apMnTmjWAMzbFClOHdBdwtns3Nd+ycreJ8c/s7IECdRtFh3VtbUBjPrUda+7g5VyXvTvIy14IYkOMmnP2Fk0V0l3C2TSfmm9ZudvGAnVbBYd5fSNAUxTaDe3lDm3A9BONOZiFtK0vqr0QDNnmXHZ7pgbpPuBs92BqvmXlDhEL1CFUHE4ajQFtRbBuUkCTUXwMh81bENSuqROTFmnaCEHyaduVrk7+7rlTgXSfcHb1npJvueUOsU1bdLbpgxkG1UYdQt3u0mgNaExlwIGNCktBvbg5YdYvpmZk/ty6gWuY5pSZ9NYvXhi6Tbrk0XQQSl0b8s6fd0gPBc6m/5R8y8ocMhaoQ6rZfVpBAG1mM7+CTYIDUPlcctU1CStQsEwQa7mx4CarIrN0PR+22ccxzuFcrrHriUmzztwaZk+seF4hPTQ4u/dvKr7lljnktkAdUs3u0goKaDOb6SSZ85cJ813Q1tlmUnfSIK0hhnmD9JDh7N7/KfiWW97Q2wJ1aEXjphcF0K7JLHHEOnQsREsTBUvVb9y+M1nYtCX9sM0+jnEO53LNGMK8QHoscM76xDz7Vrasob//y3++pjbqHFGH5FfRAZ2jwdzsHjukxwrnuXGgngsiUF+4AfbPzJZjq/Nv386lxSD0v34BOsADMlZIC84Bbv6cJDFVUA/93YYAHegBGxukBedAN37OkpkKqNf2DlpKe43Re6x5z7Pvpb3X1i8uzd69te15JkAHfMDGAmnBOeBNn9Ok5hnUY+pfL0AHfsCGDmnBOfANn/Pk8kA9xmKPcYSqAB3B04YKacE5ws2eSJJjB/VY53gRoCM9YEODtOAc6UZPLNkxgnrMsyQK0BEfsKFAWnCOeJMnmvRYQE3Necxz2AvQkR+wviEtOEe+wRNPfsigps3ZpkUe6ypQAnQHD1hfkBacO7i5yiJVYIigtumQx7yOqgDd0QPWNaQF545urLJZpcBQQG1d6Vjco49Vn1aJ4vlSdbV4AdojXqxdXUFacI51B5VuVQUA9e2Pfjt578cOzz7MR91FYBCKDb/ucrWnumXDNrMzbxplAbquqi3Pjw1pwbnlDdLlQRXAH7sGNaP3AN9dD34maFliJGarRGGzLwjQPlUi74sFacE58o1T8o0V8IGaVclDB+bWAM6swBRzCb5QdmOjrRblm/NegA6ldM10QkNacK55A3R6Lwrgpx/81KOzZo8r7vpcsnzyVDBbbMGQBz//xWBpxk6IJf34UcH2bBCgs4p0+D0UpAXnDm+asgqiwPHnXwwOaqYMTWvPi5uDrosapMAFibDuqi3tl12gRIAuEK6LQ20hLTh3cZeURywFQoKauZgBNOuhji2w/iq2UwY3CNCuGj1tN4W04NzTDVO2wRXIgppmkLymD/yeZyYbbIk9FqseW2CaUwDNggFuEKBdNXrcrgtpwbnHm6WsoylQBdRbD305ueWzq2uaLFMF4Fhwusl8ztEKVDFhbLbFst0l/wToigJ2cVpVSAvOXdwN5dGnAnmgZr/1rXZ7gbCWKYC+9cAn+zS7Vd7YThkoiwUB2pQYSFwGacF5IDdKZnSiQBbUBmeLeR4ILDgN3B75ytc7sStGJthOGSiLBQHalBhQnAdpwXlAN0mmdKoA7dFu9zwDNN30eF5scMo3njgexK6zZ88mBw4cSBYWFpJ169al29mEd+zYkR7j+K5du7KHa3/HdgDtDloRoGvL2M0FWUh/95//PcEZcUyGzHJcQQpMRQH3eTA4W0x79Lbd+1O4ff+HPwoiycGDB5OjR48mgHrDhg0piE+dWt1fm2NLS0vpMc5vG7AdQFMWCwK0KTHA2HXKX/3EXwvOA7xHMqkbBahBG5B98ftvuQDoF1cuNHmEtAr4Uks+cuTImmStFr2ysrLmWN0d2A6gN27fObtUgJ5JMcwNas4G5w/c+0hy5uy5YRoqq6RARAUOP/Z0ctsXvpnO68HcHtnPZTvvSd7zgWuT8++8G9yKY8eOpYAGxtmQ1/yRPa/Kd2wH0AubtsxOF6BnUgxvw21zBs7UHOhipOaN4d0rWRRXgbIaNM/GpR++KcoIQmrHgJj2aDcYuEPUnklXgHbVHfi2C2fanKk5A2dBeuA3TuZFU8D3ktCaO973u/emtc+Xf3ImSv72spB2ZwvUqHmRGCqoiSOUkpHTycLZasxum7Rq0pFvgpIfnAJ5tWiehet335kC2jcjXIiCWFvzyZMn0+SIqVWHqj2TqF4ShrhTkdPIg7NlK0ibEoqnosCZN8+lPZesF5PVmonZx3HrZrf85IkosvCCECDTs4NA7w3fS8M2maubXRv1Ori2DM5mgiBtSiieZwWyYAbG2WYOBrIQYg9UsfZmoAyk6XrnNneEuA8aqBJCxUhpVIWzZS9ImxKK500BlsvivYvVmInp68x+gkHaXUIr9lBv+kBTgwbMtEdbU0dI7TXUO6SaAdOqC2fLWpA2JRTPgwI8B1kw053OwGxlpC0aYOP/FrqYLAlA8wkxKMXstliTJZkSA4ubwtmKIUibEorHqkBVMLvlc+Fs+y9ON/q07Qoa0+4co2kDI5kilT7QlMEN6gftqtHxdls4m7mCtCmheEwK4P/ugrI0ZaRdSt9sNhjLJuxn8vvQgXZnas/Z4d6h8mGRAQCtCftDKdoynVBwNjMEaVNC8dAVwPdporDeGID5c3//g7Q3RhvbYy15tby8nMKZOEbQklcxVG2RZmg4mymCtCmheIgKxAKzW1ZbNJaFWJsGXgDSlEGwmnPIASlZu7RobFaRHr/HgrMVSZA2JRQPRQF83kbBWt9lasz4aujAQBWaCtZfuTk58+rrjZI3KNtLwZhwxkZsxWbfIBu1QTe6hc0uig1ns0qQNiUU96lAl2B2y2mDVu4+9JC7u/K2zV5HLTpWs4YZg43A2Z0D2o4RC9CuGhG3u4KzFUGQNiUUd62AD8wsTxWjxuwr2+mXVlLoAb5nnn3ed8og9mEbNvLBZl8QoH2qBN7XNZzNfEHalFDchQJ9g9kt4/2HH07Bd/l1NyWvvPaGe2gQ29iEbcAZW/OCAJ2nTKD9fcHZzBekTQnFMRTAv4YEZreMN++9LwXgDXvucHcPYhubgDM2FgUBukidlsf6hrOZL0ibEopDKTBkMFsZ3zp3Prn6xltTEO574LDt7j3GFuCMbdhYFAToInVaHBsKnK0IgrQpobiNAvgRExS5vTKYG6PLNuY69j/3wunk0o3XDgbSBmdswrayIECXKdTg+NDgbEUQpE0JxXUV8IEZSA8VzG75Hjv+1AzSNC300SZNntasAZyxqUoQoKuoVOOcocLZiiBImxKKqyiAvwBhm0GOfsxjAbNbPmqr1tzBy7kue3eQl70QxIYqNWezXYA2JQLEQ4ezFVGQNiUU5ymAjzCYxAUzw7PHUGPOKxPtvfbikDZg+iA3HcySl4e7n7Stn7O9ECxrc3avZ1uAzirS8PtY4GzFE6RNCcWuAvMIZrd8bFsXPKDJKD6GWjMfRqhAWqRpIwTJp6grXVG+AnSROhWPjQ3OVixB2pRQbGC2SfJpyqDGbCuWzJtCDAyxEYcpqBc3J8wox7SfzM1cN3DN4yeeTphJb/3ihaHbpEseeYNQquQhQFdRqeCcscLZiiRImxLTjPPAjF9PITD/hU2wBFD5XHLVNQmrm7AEFesEspgrK26ff+fd9MM2+zjGOZzLNXY9MWn65taoq2l0QLPSAcvRsGYYvybbdu9PNm7fmSxs2pJ+2GYfxziHc7lmDGHscDaNxwrpefYtuzexYu65u3qJ1ZinAuasrkxVylzMNum/C9uq21tv25emQVqhQhRAW2ExuGrhsuchFIKFLGwo0UhnXuBsmowF0lPwLbsnMeI8MGeXlYqR91jSHNIPf1BAD/3vQigHmTc4my5DhvRUfMvuRehYYA6taDfpBQH02gb3pbSxnEbz5g3u30sb7dcvLs1q4W0b3ENIOq9wNm2GBukp+Zbdg5CxwBxSze7Tag3oMXVZaSvvvMPZ9BkKpKfkW6Z9qPjMm+e8bcxqygilcDfpNAb0W+feHkCn77e7UWkO25zLhOsT0lPzrbJ7Ued4Fsx0m6O7nMBcR8XhnNsI0GMdNtlU9qnUnLP69AHpqflWVvOm3wGw2ytDYG6q5LCuqw3oMU880kT6qcLZtOoS0lPzLdO4TYx/ZsF8+6PfVo25jagDurYWoKndjHnqvrq6Tx3OplcXkJ6ab5m2TWMfmO/96hMCc1NBB3pdZUDPw+TXde6B4LxarZiQnppvrVa23jf8khoyA0v40JRBDZq2Z4X5U6AyoG0WqDEvH1P19gnOfqViQXpKvuVXtnwvPsnLPhfMzDYnMJdrN+YzKgHaujuNfQHGKjdKcC5WKTSkp+Rbxcr6jwrMfl2msrcU0AwUsGHYXU5yXfcGVFnCvCxNwblMoQvHQ0F6Sr5VTdmLZ+GL7rJSNGVQY0Z7hekoUApoRu8B6Lse/MzgVbHJsbG5bhCc6ykWAtJT8a06yvrAPOZJ8uuUXeeuVaAQ0Mx/AJyZeDrmygNrzWq2Bxttkuw6U/0Jzs30bgPpqfhWVWUF5qpKTeu8QkDbPKkPfv6Lo1GFlQz4UcH2KkFwrqJS/jlNIT0F38pX7eIRgfmiFtpaq0AuoJnWMa09L24OuhzMWhPC7mG5GVvRoGyqUsE5jPZ1IT0F3ypSFr0E5iKFdMwUyAU0czEDaJaBGVtg2Rlspwx5QXDOU6bZ/jxIs5/uYW6Yd99yy+pu+8DMoqxqY3ZV0rarQC6gbWUB1ugaW2CaUwDNggG+IDj7VGm/Lwtp+uhaT4Tlk6dmGcyzb80K6WygC2v7mRb0ZRaYHYG0mauAF9CsKADgWGeryXzOubl1dACbbY2w7PJZgnPcm+BC2gZVEDMMmTDPvpVV1gdmIK0ac1Ypfc9TwAto1gUE0CyGONaA7ZSBslgQnE2JuDE1Z/rtuoDmO2FefctVFDADYWrJpgHNPAKzq5K2qyjgBTSLtwI3Vqwda8B2ykBZCIJzN3fyzNmLzRoGJ4tp5phH3zJlATODSQRmU0RxWwW8gLYBBCwr3iSsrKwkBw4cSNatW5csLCwky8vLq5LhO/s5fvbs2VXHQn3BdgBNWQTnUKqWp7N498OzWqOB2WKaOer41tGjR5OlpaXUT/CVHTt2pL5EzLG+gutb2CAw93Un5j9fL6C37d6fwu37P/xRIwV27dqVnDx5MoWvQdoSOnbs2OyB41isgO0A+sN77pn93WbWLx4mhXgKAGEDcjammaOKb/GjbWA+cuTI7EfcfvTxm+yPfrwSrU3ZfOv63XemNWa3OYemDF4IKkiBEAp4Cblx+84Ubi+u/Lh1HsCaB+rUqVPpg0bNmQcNgFMTihWw/ZIP3Zj88u1/ngJDcI6l9Op0fYD+yMEvzaB9+e/sLfUt85lsLRmfwZf48C+tr4Bv/eKmrTPf4ocIMPNPTUEKhFTAC+iFTVvSh+j8O++2zouHzGo8ABk4dxGwnYcoW4vT9wvzCPehw56/+VZy2bbbCn3L/mH5frwN0Bs2bOjChXLzwLf4d/be3z8oMOeqpAMhFCgENKPy2gb3oeJva6w256yds4fo5xOb9wEk5Xnxx4BmACaa/6Xf+GgKtzzfsqYNXxOGwZsadp/BfGvhg1v7NEN5T0ABL6CtiePln5wJIkEff0v5G0oth7IodKdAtonDwGyrShf5Fs0W5iu+H3LaozmebfrornQXcpJvda34dPPzAtpe5NSZES5PQqtB82BVCdSc+AvLdW2CvcihLArdKWCAzoLZLCjyLashU4v2Batd5/kGUAfivOeoG0iTZhWuLwvyrTKFdDyUAl5qWleo5SdPtMqHGhEPC44PoPMeLDKxB8RqUEXnVjEq2xWqyjU6p70CvIwtWlW6yLeshlzU/pz3Q28/7OY/VUvidgnl2iqAlm9VVVfntVXAC+gQgwmsqxQOz8NT5Pycw0MJlA8ePFgK8yqFzg5UqXKNzmmvQFk3xiLfKgK0/cj74M0+Xj4DW6tlVykJ/sa/NfzTau9VAC3fqqKuzgmhgBfQbYbjAmJ7UOyvKl3s2J/3csdtb7SHtG0N2jfUO4RgSqOdAkW+ZZDMQhifsD7Qvl5Arv8YyKtaadfib0WVCDc9+ZarhrZjKuAFdNMJbQzEODpNG4DaAjUVgzcPQ/YhtPNCALposiTLR3E/ChT5FrDEb/AT6zdvcDaAAmjOYz+fbKgLaLve0velaecQy7dcNbQdWwEvoMn04pSQT1e2wZwcGPOAuYG/kfbwUZN24e2exwPCA0paTQNTpNKDgzIoDE+BIt/ivtuPOf/AqFUTgLLtJ8ZPrPbrljA2oOVbrtrajq1ALqBtUnUmv+8yhAA0iwwA6KIJ+7ssk/JarUBM34oNaPnW6nupb3EVyAV0X8sStQV0nSWv4kqr1PMUiOlbMQEt38q7o9ofS4FcQJOhLezJQqxdhbaArrtobFflUj6rFYjlWzEBLd9afQ/1Lb4ChYBmoApNBeuv3JycefX16NbQLm0PGKCuG7ARW7E5xCCbuvnr/OoKxPAt3nvYew7fOwz78c9aSVu2de/k/YivbVu+lVVN37tQoBDQGGADC+4+9FA0e+zlIi8Hsx+AXTVgI3DGZoXhKxDKtwy8Wd/hu/tDb+e5yviusX3uefItVw1td6VAKaBPv7SSQg/wPfPs813ZVTsfbMNGPtisMHwFuvYtfuypKdcN8q26iun8UAqUApqM7j/8cAq+y6+7KXnltTdC5R0sHWzCNuCMrQrjUaAr36KbZxM4y7fG40vzaGklQFPwm/felwLwhj13DE4HbALO2KgwPgXkW+O7Z7K4GwUqA/qtc+eTq2+8NQXhvgcOd2NdhVywBThjGzYqjE8B+db47pks7kaByoDGnOdeOJ1cuvHawUDa4IxN2KYwXgXkW+O9d7I8ngK1AI0Zjx1/agZpmhb6aJMmT2vWAM7YpDB+BeRb47+HKkFYBWoDmuyp7VhzBy/nuuzdQV72QhAbVHMO6xB9pybf6vsOKP8hKdAI0BSAdkN7uUMbMP1EYw5mIW3ri2ovBNXmPCRXCmeLfCuclkpp3Ao0BrQV27pJAU1G8TEcNm9BULumTkxapGkjBMlHXenqKDjec+Vb4713sjyMAq0BjRkMOLBRYSmoFzcnzPrF1IzMn1s3cM3jJ55OmElv/eKFodukSx4ahFJXzXGfL98a9/2T9e0UCAJoM4H5FWwSHIDK55KrrklYgYJlgljLjQU3WRWZpev5sM0+jnEO54cdjW8AAACWSURBVHKNXU9Mmppbw1SeZizfmuZ9n3qpgwLaxGQ6Seb8tYnZXdhW3d562740DdJSkAKmgHzLlFA8BQWiANoVjiWOWIeOxUJpoti2e3+ycfvOZGHTlvTDNvs4xjmcyzUKUqBMAflWmUI6PnYFogN67ALJfikgBaRAXwoI0H0pr3ylgBSQAiUKCNAlAumwFJACUqAvBf4fWF9dxQsOr/0AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 1 - Backpropagation (80 Pts)\n",
    "\n",
    "Some help: https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\n",
    "\n",
    "1. Fully Connected Neural Networks (FCNNs):\n",
    "- FCNNs, also known as dense networks, are the most straightforward type of neural networks.\n",
    "- Each layer in an FCNN represents a simple operation involving matrix-vector multiplication (using weights) followed by a non-linearity (activation function).\n",
    "- Specifically:\n",
    "    - Given an input vector (previous layer’s activation), we compute the output of a layer by multiplying it with a weight matrix.\n",
    "    - Then, we apply a non-linear activation function to the resulting vector.\n",
    "- This process is repeated for each layer in the network.\n",
    "\n",
    "2. Deriving the Output:\n",
    "- In the first part of your task, you’ll be asked to write down the output of the network in terms of its inputs.\n",
    "- Essentially, you’ll follow the forward pass through the layers, applying the weight matrices and activation functions to compute the final output.\n",
    "\n",
    "3. Calculating the gradient of the weights:\n",
    "- In the second part, we’ll focus on computing the derivatives of each weight.\n",
    "- Specifically, we’ll find how the loss function changes with respect to each weight in the network.\n",
    "- These derivatives are crucial for training the network using techniques like gradient descent.\n",
    "\n",
    "4. Optimizing the Network:\n",
    "- We will update the weight using gradient descent. \n",
    "- I have already written the training code using your implementations, If everything goes right, our network will learn the pattern in the data. \n",
    "\n",
    "Notes:\n",
    "- Please show your calculations. You can submit your hand written solutions as screenshots inside the notebook, or use the latex functionality of the notebook. \n",
    "- Please don't forget to answer **short** open-ended questions after part 3.\n",
    "\n",
    "Consider the following simple network:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Where each node (circle) shows an activation/input and each line represents a weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 Part A - Forward Pass\n",
    "\n",
    "**Derivation:**\n",
    "\n",
    "Write the output of the network y, as a function of its inputs $x_0$ and $x_1$ (You can show it as a vector with a line $\\overline{x}$). For the ease of grading, call your weights at layer i as $W_i$ and activation function as $\\sigma$. Also, you can show your weighted sums (results of matrix multiplications before activation) as $\\overline{z_i}$ and activations as $\\overline{a_i}$ at layer i.\n",
    "\n",
    "Assumptions:\n",
    "- The network has sigmoid activation function after each layer. $\\sigma(x) = \\frac{1}{1+e^{-x}}$\n",
    "- No biasses. $b_i$ does not exist. This should simplfy the derivative on the next part. \n",
    "\n",
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**\n",
    "\n",
    "In this section you will implement the solution you had written down. The structure for your code is already provided in q1.py. Below you can check if you pass the autograder or not. Please do not hardcode the number of hidden units. We will be modifying it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(q1)\n",
    "importlib.reload(autograder)\n",
    "autograder.test_sigmoid()\n",
    "autograder.test_networkInitialization()\n",
    "autograder.test_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 Part B - Bacward pass (Backpropagation)\n",
    " \n",
    " In this section we will test the results of our output using a loss function. Loss function is a differentiable scalar metric that tells us and the network how it is performing. Smaller values of loss function indicate better performance. By taking the derivative of the loss function with respec to to our learnable parameters (weights), we can optimize the network to follow the patterns in our data. \n",
    "\n",
    " Calculation of backpropagation (i.e. the derivatives) can be difficult if you are rusty with linear algebra and calculus. I highly recommend joining the office hours if you are having trouble. \n",
    "\n",
    "- Help: https://towardsdatascience.com/deriving-the-backpropagation-equations-from-scratch-part-1-343b300c585a\n",
    "- Help: https://medium.com/binaryandmore/beginners-guide-to-deriving-and-implementing-backpropagation-e3c1a5a1e536\n",
    "\n",
    " Calculate $\\frac{\\partial L}{\\partial W_1}$ and $\\frac{\\partial L}{\\partial W_2}$. More detailed definition of $L$ is given below. \n",
    "\n",
    " **Assumptions**:\n",
    " - After each linear layer we have a sigmoid activation function. \n",
    " - Loss function is L2 loss: $L2(y_{label}, y_{prediction}) = \\frac{1}{2 \\times numberOfExamples}(y_{label}-y_{prediction})^2$\n",
    "\n",
    " **Step by step:**:\n",
    " - Start by calculating the derivative of sigmoid. Assign a new name for this function (such as $\\sigma^\\prime_{}$)\n",
    " - Second step should be calculating $\\frac{\\partial L}{\\partial W_2}$ and $\\frac{\\partial L}{\\partial a_1}$.\n",
    " - By chain rule use $\\frac{\\partial L}{\\partial a_1}$ from previous step to calculate $\\frac{\\partial L}{\\partial W_1}$\n",
    "\n",
    "\n",
    " **Tips:**\n",
    " - Calculate the derivative of sigmoid in terms of sigmoid.\n",
    " - Derivative of $A\\overline{x}$ w.r.t. $\\overline{x}$ is $A$.\n",
    " - Derivative of $A\\overline{x}$ w.r.t. $A$ is $\\overline{x}^T$.\n",
    " \n",
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation:**\n",
    "\n",
    "Now go back to q1.py and implement backward pass. Later run the code block below to check if your implementations are accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(q1)\n",
    "autograder.test_L2Loss()\n",
    "autograder.test_sigmodDerivative()\n",
    "autograder.test_backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 Part C - Updating the weights\n",
    "In this part there is no derivation to do. You need to implement gradient descent update equation. The update equation is given by: $W_i = W_i - LR \\cdot \\frac{\\partial L}{\\partial W_i}$\n",
    "\n",
    "Finally implement predict(), in this function we make guesses. \n",
    "\n",
    "If you pass all the tests including the one below, proceed to the final part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(q1)\n",
    "autograder.test_updateWeights()\n",
    "autograder.test_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 Part D - Training and Experimenting\n",
    "\n",
    "In this part we will train our network and do some experiments. Most of the code is implemented for you. \n",
    "\n",
    "\n",
    "Run the code below to display the data, our task is to classify these points according to their color based on their coordinate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(q1)\n",
    "X,y,X_test,y_test = q1.loadDataset()\n",
    "q1.displayData(X, y, title = \"Training Data\")\n",
    "q1.displayData(X_test, y_test, title = \"Test Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(q1)\n",
    "network = q1.FCNN(2,4,1, init='random')\n",
    "lossList = network.train(X, y, 2000, 1.0)\n",
    "q1.plotTrainingLoss(lossList)\n",
    "q1.analyzeResults(X_test, y_test, network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Open End Questions\n",
    "\n",
    "After you’ve answered the questions below, make sure to return your code to its original state that passes the autograder before submitting.\n",
    "\n",
    "- **1:** \n",
    "    - In the plot shown earlier, you observed a linear decision boundary with only 2 neurons in the hidden layer. However, this boundary is limited due to the network’s simplicity, resulting in underfitting.\n",
    "    - To improve the decision boundary, let’s increase the number of neurons in the hidden layer. You can achieve this by modifying the second argument of q1.FCNN() in the code block above.\n",
    "    - Once you’re satisfied with the decision boundary, please report the number of neurons you used and provide a screenshot of the new decision boundary.\n",
    "\n",
    "    - Bonus (10 Pts): Between the input and hidden layer, replace the Sigmoid activation function with the ReLU activation function. After making this change, repeat question 1 described above. Remember to modify both the forward and backward functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2:**\n",
    "    - Instead of initializing the weights in your network using a gaussian random distribution, consider initializing them to all zeros.\n",
    "    - To achieve this, you can modify the ‘init’ parameter of the q1.FCNN() class. \n",
    "    - Did the network learn anything? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2 - Clustering (20 Pts)\n",
    "- K-Means Clustering Overview:\n",
    "    - In this question, we’ll explore the k-means clustering algorithm.\n",
    "    - K-means is an unsupervised algorithm, meaning that our data doesn’t come with any predefined labels. Instead, we aim to group similar data points together.\n",
    "    - However, k-means can be sensitive to local minima during optimization.\n",
    "- Random Initialization for Stability:\n",
    "    - To mitigate the issue of local minima, it’s a best practice to initialize the algorithm multiple times (at least k times, where k is the number of clusters).\n",
    "    - Each initialization starts from different random centroids, increasing the chances of finding a better solution.\n",
    "- Optimization Loop:\n",
    "    - The optimization process in k-means is straightforward and doesn’t involve complex mathematics.\n",
    "    - Here’s how it works:\n",
    "        - Load Data: We load our dataset. (Implemented for you)\n",
    "        - Random Initialization: We randomly initialize the centroids. (Implemented for you)\n",
    "        - Iterate Until Convergence:\n",
    "        - Assign Data Points: For each example in the dataset, we assign it to the closest centroid. (You will implement it)\n",
    "        - Update Centroids: We update the centroid locations by taking the average of the examples assigned to each centroid. (You will implement it)\n",
    "        - The cost we are optimizing over is the total L2 distance between each data point and its cluster centroid. We will check convergence using this cost function. \n",
    "\n",
    "Once you pass the autograder by running the next code block, you can move on to the next section part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(q2)\n",
    "autograder.test_assignClusters()\n",
    "autograder.test_updateClusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example run of the KMeans algorithm:\n",
    "importlib.reload(q2)\n",
    "data = q2.loadDataset()\n",
    "best_clusters, best_assignments, minCost = q2.trainKMeans(data, 4, 100)\n",
    "q2.visualizeResult(data, best_clusters, best_assignments, minCost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the class, we explored an algorithm called elbow detection to determine the optimal number of clusters in k-means. For the next question, you’ll create two figures related to the parameter k:\n",
    "- Visualizing Clustering Results:\n",
    "    - In the first figure, visualize the clustering results for different numbers of centroids (values of k) (1 to 8 is fine).\n",
    "- Plotting Loss for a Range of k Values:\n",
    "    - In the second figure, plot the loss (e.g., sum of squared distances) for a range of k values.\n",
    "    - Observe how the loss changes as k varies.\n",
    "\n",
    "Discuss whether the elbow detection algorithm is effective. Does it work well for determining the optimal k?\n",
    "\n",
    "Show your results below, please keep the code you used to generate the results in your submission (You probably should create a new function q2.py). Submissions without source code will not be graded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3 - Autoencoders and Visualizing the Latent Space\n",
    "\n",
    "- Autoencoder Overview:\n",
    "    - In this question, you’ll train an autoencoder.\n",
    "    - All the required functions for training are already provided.\n",
    "- The autoencoder consists of:\n",
    "    - An encoder with 2 hidden layers that projects the image onto a 2-dimensional latent space.\n",
    "    - A decoder with 2 hidden layers that recovers the image from its latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(q3)\n",
    "encoder, decoder = q3.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(q3)\n",
    "latentSpace = q3.plotEncoderMap(encoder, q3.loadMNIST())\n",
    "q3.plotDecoderMap(decoder, latentSpace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- Analysis:\n",
    "    - Latent Space Map's for the Decoder and Encoder network give us an insight about how the network works. \n",
    "    - Randomly train the network couple of more times. \n",
    "    - What are some common trends that you observe on latent space map's after each distinct training? \n",
    "- Number generation:\n",
    "    - On the latent space of encoder, pick two distinct numbers.\n",
    "    - Using the coordinate axis, locate the middle of the two numbers. (Make sure the middle region is not occupied by another number)\n",
    "    - Input the middle location to the decoder. \n",
    "    - How does your output look? Does it match your expectation?\n",
    "    - Show your results using screenshots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q4: Project Research\n",
    "\n",
    "You've submitted a preliminary bibliography that connects a series of papers around a theme. Select an \"anchor paper\" that feels central to your topic and read it using some of the tools covered in our \"how to read a paper\" reading (note: I do not expect you to get to the part where you're reimplementing the papers, just to the point that you understand their main arguments). A new tool that we will introduce to help scaffold your understanding is \"Heilmeir's catechism\". Electrical engineer George H. Heilmeier developed a set of questions that anyone proposing a research project should be able to answer:\n",
    "\n",
    "1. What are you trying to do? Articulate your objectives using absolutely no jargon.\n",
    "2. How is it done today, and what are the limits of current practice?\n",
    "3. What's new in your approach and why do you think it will be successful?\n",
    "4. Who cares? If you're successful, what difference will it make?\n",
    "5. What are the risks and the payoffs?\n",
    "6. How much will it cost? How long will it take? [You can ignore this.]\n",
    "7. What are the midterm and final \"exams\" to check for success?\n",
    "\n",
    "Attempt to answer these questions from the point of view of your anchor paper's authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bookkeeping:\n",
    "\n",
    "**Graduate/Undergraduate**:\n",
    "\n",
    "**Estimated time spent on this assignment:**\n",
    "\n",
    "**Optional Feedback:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(q1)\n",
    "importlib.reload(q2)\n",
    "importlib.reload(autograder)\n",
    "autograder.gradeAll()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS396Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
